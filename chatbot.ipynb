{"cells":[{"cell_type":"markdown","id":"0a2a9058","metadata":{},"source":["# Chatbot using LLM"]},{"cell_type":"markdown","id":"97f4fa8d","metadata":{},"source":["## Objective\n","\n","The objective of this project is to develop a chatbot that provides assistance based on user queries using LLaMA 3 API's. The key components of this project are as follows:\n","\n","1. **Ollama**:\n","   - Utilize Ollama to run and manage large language models, including LLaMA 3.\n","\n","2. **User-Friendly Interface**:\n","   - Develop an intuitive user interface using Gradio, allowing users to easily input their queries and receive prompt, relevant responses.\n","   - Ensure the interface is accessible and responsive, enhancing the overall user experience."]},{"cell_type":"markdown","id":"2ff3d157","metadata":{},"source":["## Installations\n","\n","To set up the chatbot, the following libraries and tools are required:\n","\n","1. **Python**: Ensure Python (version 3.7 or later) is installed on your system.\n","\n","2. **Ollama**: \n","   - Ollama provides an easy way to run and manage large language models, including LLaMA 3. Ensure you follow the [installation instructions from the Ollama website](https://ollama.com/download) to get started.\n","\n","3. **Gradio**: A library for creating user interfaces for machine learning models.\n","\n","3. **Langchain**: A library for creating user interfaces for machine learning models.\n","\n","\n","4. **Other Required Libraries**: Ensure any additional libraries needed for specific functionalities are also installed."]},{"cell_type":"code","execution_count":null,"id":"cf8ab323","metadata":{},"outputs":[],"source":["# %pip install gradio langchain_community"]},{"cell_type":"markdown","id":"b0bc54fc","metadata":{},"source":["## Chatbot Implementation"]},{"cell_type":"code","execution_count":5,"id":"d250a515","metadata":{},"outputs":[],"source":["from langchain_community.chat_models import ChatOllama\n","\n","import time\n","\n","llm = ChatOllama(model=\"llama3\", show_progress=True)\n","\n","def get_answer(question):\n","    if not question:\n","        return \"Please enter a question.\"\n","    \n","    try:\n","        answer = llm.predict(question)\n","        for i in range(1, len(answer) + 1):\n","            yield answer[:i]  # Yield progressively longer substrings of the answer\n","            time.sleep(0.05)  # Control the typing speed\n","    except Exception as e:\n","        yield f\"Error occurred: {str(e)}\"\n","\n"]},{"cell_type":"markdown","id":"4faffa73","metadata":{},"source":["## Create the Gradio Interface"]},{"cell_type":"code","execution_count":6,"id":"edf939fb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on local URL:  http://127.0.0.1:7862\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"text/html":["<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"name":"stderr","output_type":"stream","text":["C:\\Users\\gokul\\AppData\\Local\\Temp\\ipykernel_15224\\268499743.py:12: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  answer = llm.predict(question)\n"]}],"source":["import gradio as gr\n","with gr.Blocks() as iface:\n","    gr.Markdown(\"<h1 style='text-align: center;'>Chatbot Using OLLaMA</h1>\")\n","    \n","    with gr.Row():\n","        question_input = gr.Textbox(label=\"Enter your question:\", lines=2, placeholder=\"Type your question here...\")\n","        \n","    submit_button = gr.Button(\"Submit\")\n","    answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n","    \n","    # Define what happens when the button is clicked\n","    submit_button.click(get_answer, inputs=question_input, outputs=answer_output, show_progress=True)\n","\n","iface.launch()"]},{"cell_type":"code","execution_count":null,"id":"69e0bb8b","metadata":{},"outputs":[],"source":["iface.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}
